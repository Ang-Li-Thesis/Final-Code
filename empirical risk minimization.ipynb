{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from model import model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import FastFood as FF\n",
    "from sklearn import svm, metrics, datasets, preprocessing\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "# from cvxopt import normal\n",
    "# from cvxopt.modeling import variable, op, max, sum\n",
    "# import pylab\n",
    "from scipy.optimize import minimize\n",
    "import cvxpy as cp\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from pulp import *\n",
    "from sklearn.preprocessing import StandardScaler  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta        = 1.\n",
    "delta      = 0.001\n",
    "h = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test model\"\"\"\n",
    "def testModel(X, y, beta):\n",
    "    ypred = np.dot(X, beta) \n",
    "    ypred[ypred >= 0] = 1\n",
    "    ypred[ypred < 0] = -1\n",
    "    pred_error = 1 - np.abs(metrics.accuracy_score(y.flatten(), ypred))\n",
    "    return pred_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Non-private solution\"\"\"\n",
    "\n",
    "def non_private(X, y, lambda2, T, epsilon, h):\n",
    "    m, n = X.shape[0], X.shape[1]\n",
    "    beta = np.zeros((n, 1)) \n",
    "    def huber_loss(w):\n",
    "        m, n = X.shape[0], X.shape[1]        \n",
    "        z = np.multiply(y, np.reshape(X.dot(w),(m,1)))\n",
    "        obj = 0\n",
    "        for i in range(m):\n",
    "            if z[i,0] > (1+h):\n",
    "                obj = obj\n",
    "            elif np.abs(1 - z[i,0]) <= h:\n",
    "                obj += (1 - z[i,0] + h)**2/(4*h) \n",
    "            elif z[i,0] < (1-h):\n",
    "                obj += 1 - z[i,0]\n",
    "        return obj/m + lambda2 * (np.linalg.norm(w) ** 2)/2\n",
    "    w0 = np.ones(n)\n",
    "    res = minimize(huber_loss, w0, method='Nelder-Mead', tol = 1e-09)\n",
    "    beta = res['x']\n",
    "    beta = np.reshape(np.array(beta), (n,1))\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Noise generator\"\"\"\n",
    "def noise(scale,Length):\n",
    "    res = np.random.laplace(0, 1/scale, Length) #Generate the norm of noise according to gamma distribution\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Objective perturbation\"\"\"\n",
    "def objective_pert(X, y, lambda2, T, epsilon, h):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # huber loss\n",
    "    c = 1/(2*h)\n",
    "\n",
    "    epsilon2 = epsilon - np.log(1+2*c/(m*lambda2)+(c**2/((m*lambda2)**2)))\n",
    "    if epsilon2 > 0:\n",
    "        Delta = 0\n",
    "    else:\n",
    "        Delta = c / (m * (np.exp(epsilon/4)-1)) - lambda2\n",
    "        epsilon2 = epsilon / 2\n",
    "    b = noise(epsilon2/2,n)\n",
    "    def huber_loss(w):\n",
    "        m, n = X.shape[0], X.shape[1]        \n",
    "        z = np.multiply(y, np.reshape(X.dot(w),(m,1)))\n",
    "        obj = 0\n",
    "        for i in range(m):\n",
    "            if z[i,0] > (1+h):\n",
    "                obj = obj\n",
    "            elif np.abs(1 - z[i,0]) <= h:\n",
    "                # huber loss\n",
    "                obj += (1 + h - z[i,0])**2/(4*h)\n",
    "\n",
    "            elif z[i,0] < (1-h):\n",
    "                obj += 1 - z[i,0]\n",
    "        return obj/m + lambda2 * (np.linalg.norm(w) ** 2)/2 + np.array(b).dot(w)/m + Delta*(np.linalg.norm(w) ** 2)/2\n",
    "    w0 = np.ones(n)\n",
    "    res = minimize(huber_loss, w0, method='Nelder-Mead', tol = 1e-09)\n",
    "    beta = res['x']\n",
    "    beta = np.reshape(np.array(beta), (n,1)) \n",
    "    return beta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Output perturbation\"\"\"\n",
    "def output_pert(X, y, lambda2, T, epsilon, h):\n",
    "    m, n = X.shape\n",
    "    def huber_loss(w):\n",
    "        m, n = X.shape[0], X.shape[1]        \n",
    "        z = np.multiply(y, np.reshape(X.dot(w),(m,1)))\n",
    "        obj = 0\n",
    "        for i in range(m):\n",
    "            if z[i,0] > (1+h):\n",
    "                obj = obj\n",
    "            elif np.abs(1 - z[i,0]) <= h:\n",
    "                obj += (1 - z[i,0] + h)**2/(4*h) \n",
    "            elif z[i,0] < (1-h):\n",
    "                obj += 1 - z[i,0]\n",
    "        return obj/m + lambda2 * (np.linalg.norm(w) ** 2)/2\n",
    "    w0 = np.ones(n)\n",
    "    res = minimize(huber_loss, w0, method='Nelder-Mead', tol = 1e-09)\n",
    "    beta = res['x']\n",
    "    beta = np.reshape(np.array(beta), (n,1))\n",
    "    b = noise((lambda2 * epsilon * m)/2,n)\n",
    "    beta = np.reshape(beta, (n,1)) + np.reshape(b,(n,1))\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Random Kitchen Sinks kernel approximation\"\"\"\n",
    "def random_kitchen_sink(X, n):\n",
    "    m, d = X.shape\n",
    "    gamma = 1 / (d * X.var())\n",
    "    W = np.random.randn(d, n)*np.sqrt(2 * gamma)\n",
    "    b = np.random.uniform(-np.pi, np.pi, n)\n",
    "    X_features = np.sqrt(2/n) * np.cos(X.dot(W) + b)\n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAggregateModel(X, y, modelName, methodName, Lambda, kernel, features, epsilons):\n",
    "    switch = {\n",
    "        \"output_pert\"          : output_pert,\n",
    "        \"objective_pert\"       : objective_pert\n",
    "    }\n",
    "    X = approximation(X, kernel, features)\n",
    "    normX = np.max(np.linalg.norm(X, axis=1))\n",
    "    X = X/normX\n",
    "    fun = switch.get(modelName)\n",
    "    average_acc, betas_pri = [], []\n",
    "    for epsilon in epsilons:\n",
    "        errors = []\n",
    "        for lambda2 in Lambda:\n",
    "            error_cv = crossValidate(X, y, modelName, lambda2, T, epsilon, h, kernel, features)\n",
    "            print('mean train error: ' + str(error_cv))\n",
    "            errors.append(error_cv)\n",
    "        p = np.argmin(errors)\n",
    "        print(errors)\n",
    "        #smallest error for each epsilon\n",
    "        error_epsilon = errors[p] \n",
    "        # best lambda havinf smallest error\n",
    "        lambda_opt = Lambda[p] \n",
    "        #get best beta using best lambda\n",
    "        beta_opt = fun(X, y, lambda_opt, T, epsilon, h)      \n",
    "        print(\"Relative Error is : \" + str(error_epsilon) + ' when epsilon is ' + str(epsilon) + ' and lambda is ' + str(lambda_opt))\n",
    "        betas_pri.append(beta_opt)\n",
    "        average_acc.append(error_epsilon)\n",
    "    plt.plot(average_acc)\n",
    "    plt.show()\n",
    "    return average_acc, beta_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNonPrivateModel(X, y, modelName, Lambda, kernel, features):\n",
    "\n",
    "    errors_cv, errors_svm = [], []\n",
    "    epsilon = 0\n",
    "    X = approximation(X, kernel, features)\n",
    "    for lambda2 in Lambda:\n",
    "        errors_iteration_cv, errors_iteration_svm = [], []\n",
    "        error_iteration_cv = crossValidate(X, y, modelName, lambda2, T, epsilon, h, kernel, features)\n",
    "        print('mean train error: ' + str(error_iteration_cv))\n",
    "        errors_cv.append(error_iteration_cv)\n",
    "\n",
    "    clf = svm.SVC(gamma='scale')\n",
    "    scores = cross_val_score(clf, X, y.flatten(), cv=10)\n",
    "    errors_svm = np.mean([1 - score for score in scores])\n",
    "    \n",
    "    p_cv = np.argmin(errors_cv)\n",
    "    \n",
    "    error_epsilon_cv = errors_cv[p_cv] \n",
    "    \n",
    "    lambda_opt_cv = Lambda[p_cv]\n",
    "    \n",
    "    print(\"Relative Error is : \" + str(error_epsilon_cv) + ' when lambda is ' + str(lambda_opt_cv) + ' using optimal solver')\n",
    "    print(\"Relative Error is : \" + str(errors_svm) + ' using svc')\n",
    " \n",
    "    beta_opt = non_private(X, y, lambda_opt_cv, T, epsilon, h)\n",
    "    return error_epsilon_cv, errors_svm, beta_opt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(X, y, modelName, lambda2, T, epsilon, h, kernel, features):\n",
    "    switch = {\n",
    "        \"non_private\"          : non_private,\n",
    "        \"output_pert\"          : output_pert,\n",
    "        \"objective_pert\"       : objective_pert,\n",
    "    }\n",
    "    fun = switch.get(modelName)\n",
    "         \n",
    "    kf = KFold(n_splits=10)\n",
    "    errors_cv = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        xtrain, ytrain = X[train_index], y[train_index]\n",
    "        xtest, ytest = X[test_index], y[test_index]\n",
    "        m, d = xtrain.shape[0], xtrain.shape[1]\n",
    "        \n",
    "        beta = fun(xtrain, ytrain, lambda2, T, epsilon, h)\n",
    "        error = testModel(xtest, ytest, beta)\n",
    "        print('train error: ' + str(error))\n",
    "        errors_cv.append(error)\n",
    "    return np.mean(errors_cv, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Kernel approximation method selection\"\"\"\n",
    "def approximation(X, kernel, n):\n",
    "    if kernel == 'random kitchen sinks':\n",
    "        X_kernel = random_kitchen_sink(X, n)\n",
    "    elif kernel == 'FastFood':\n",
    "        m, d = X.shape[0], X.shape[1]\n",
    "        X_kernel = FF.fastfood_forkernel(X, n)\n",
    "        X_kernel = X_kernel[:,0:n]\n",
    "    return X_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('adult_data.csv',sep = ';')\n",
    "n = adult.shape[0]\n",
    "X = adult[adult.columns[0:adult.shape[1]-1]]\n",
    "y = adult[adult.columns[adult.shape[1]-1:adult.shape[1]]]\n",
    "y = np.reshape(np.array(y),(n, 1))\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "cols = X.columns\n",
    "X = X.iloc[:10000]\n",
    "y = y[:10000]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(np_scaled, columns = cols)\n",
    "# X.iloc[:,:] = preprocessing.Normalizer(norm='l2').fit_transform(X)\n",
    "X = X.values\n",
    "# y = preprocessing.normalize(y, norm='l2')\n",
    "normX = np.max(np.linalg.norm(X, axis=1))\n",
    "X = X/normX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Label rate is ' + str(np.sum(y==1)/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kddcup99 = pd.read_csv('kddcup99.csv', sep = ';')\n",
    "n,d = kddcup99.shape\n",
    "y = np.reshape(np.array(kddcup99['label']),(n, 1))\n",
    "X = kddcup99.drop(columns = ['label'])\n",
    "X, y = shuffle(X, y, random_state = 0)\n",
    "\n",
    "X = X.iloc[:15000]\n",
    "y = y[:15000]\n",
    "\n",
    "cols = X.columns\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(np_scaled, columns = cols)\n",
    "X.iloc[:,:] = preprocessing.Normalizer(norm='l2').fit_transform(X)\n",
    "X = X.values\n",
    "\n",
    "y = preprocessing.normalize(y, norm='l2')\n",
    "# X, y = shuffle(X, y, random_state = 0)\n",
    "\n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print('Label rate is ' + str(np.sum(y==1)/15000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Nonprivate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='scale')\n",
    "scores = cross_val_score(clf, X, y.flatten(), cv=10)\n",
    "errors_svm = np.mean([1 - score for score in scores])\n",
    "errors_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, d = X.shape\n",
    "n = d\n",
    "kernel = 'FastFood'\n",
    "epsilons = [0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select best Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pri = 'non_private'\n",
    "print(non_pri)\n",
    "print('##############')\n",
    "Lambda = [10**(-10), 10**(-7), 10**(-4), 10**(-3.5), 10**(-3), 10**(-2.5), 10**(-2), 10**(-1.5)]\n",
    "t0 = time.time()\n",
    "error_nonpriv_ff_cv, error_nonpriv_ff_svm, beta_opt_nonpriv = trainNonPrivateModel(X, y, non_pri, Lambda, kernel, n)\n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = 'objective_pert'\n",
    "print(obj)\n",
    "print('##############')\n",
    "\n",
    "Lambda = [10**(-10), 10**(-7), 10**(-4), 10**(-3.5), 10**(-3), 10**(-2.5), 10**(-2), 10**(-1.5)]\n",
    "t0 = time.time()\n",
    "error_ff_obj_best_lambda, beta_opt_obj = trainAggregateModel(X, y, obj, kernel, Lambda, kernel, n, epsilons)\n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 'output_pert'\n",
    "print(out)\n",
    "print('##############')\n",
    "Lambda = [10**(-10), 10**(-7), 10**(-4), 10**(-3.5), 10**(-3), 10**(-2.5), 10**(-2), 10**(-1.5)]\n",
    "errors = []\n",
    "t0 = time.time()\n",
    "error_ff_out_best_lambda, beta_opt_out = trainAggregateModel(X, y, obj, kernel, Lambda, kernel, n, epsilons)\n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use fixed Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = 'objective_pert'\n",
    "print(obj)\n",
    "print('##############')\n",
    "\n",
    "Lambda = [0.00031622776601683794]\n",
    "t0 = time.time()\n",
    "error_ff_obj_fixed_lambda, beta_opt_obj = trainAggregateModel(X, y, obj, kernel, Lambda, kernel, n, epsilons)\n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 'output_pert'\n",
    "print(out)\n",
    "print('##############')\n",
    "Lambda = [0.0031622776601683794]\n",
    "t0 = time.time()\n",
    "error_ff_out_fixed_lambda, beta_opt_out = trainAggregateModel(X, y, out, kernel, Lambda, kernel, n, epsilons)\n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Kitchen Sinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'random kitchen sinks'\n",
    "m, d = X.shape\n",
    "n = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select best Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pri = 'non_private'\n",
    "print(non_pri)\n",
    "print('##############')\n",
    "Lambda = [10**(-10), 10**(-7), 10**(-4), 10**(-3.5), 10**(-3), 10**(-2.5), 10**(-2), 10**(-1.5)]\n",
    "t0 = time.time()\n",
    "error_nonpriv_rks_cv, error_nonpriv_rks_svm, beta_opt_nonpriv_rks = trainNonPrivateModel(X, y, non_pri, Lambda, kernel, n)\n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = 'objective_pert'\n",
    "print(obj)\n",
    "print('##############')\n",
    "Lambda = [10**(-10), 10**(-7), 10**(-4), 10**(-3.5), 10**(-3), 10**(-2.5), 10**(-2), 10**(-1.5)]\n",
    "t0 = time.time()\n",
    "error_rks_obj_best_lambda, beta_obj_nonpriv_rks = trainAggregateModel(X, y, obj, kernel, Lambda, kernel, n, epsilons)\n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 'output_pert'\n",
    "print(out)\n",
    "print('##############')\n",
    "Lambda = [10**(-10), 10**(-7), 10**(-4), 10**(-3.5), 10**(-3), 10**(-2.5), 10**(-2), 10**(-1.5)]\n",
    "t0 = time.time()\n",
    "error_rks_out_best_lambda, beta_out_nonpriv_rks = trainAggregateModel(X, y, out, kernel, Lambda, kernel, n, epsilons)\n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use fixed Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = 'objective_pert'\n",
    "print(obj)\n",
    "print('##############')\n",
    "Lambda = [0.0001]\n",
    "t0 = time.time()\n",
    "error_rks_obj_fixed_lambda = trainAggregateModel(X, y, obj, kernel, Lambda, kernel, n, epsilons)\n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = 'output_pert'\n",
    "print(out)\n",
    "print('##############')\n",
    "Lambda = [0.01]\n",
    "t0 = time.time()\n",
    "error_rks_out_fixed_lambda = trainAggregateModel(X, y, out, kernel, Lambda, kernel, n, epsilons)   \n",
    "t1 = time.time()\n",
    "print('Runtime : ' + str(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Best Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "error_ff = [error_nonpriv_ff_cv] * 11\n",
    "\n",
    "plt.plot(epsilon, error_ff)\n",
    "plt.plot(epsilon, error_ff_obj_fixed_lambda)\n",
    "plt.plot(epsilon, error_ff_out_fixed_lambda)\n",
    "# plt.ylim(0.15, 0.45)\n",
    "my_xticks = ['0.01', '0.05', '0.1', '0.15', '0.2', '0.25', '0.3', '0.35', '0.4', '0.45', '0.5']\n",
    "plt.xticks(epsilon, my_xticks)\n",
    "plt.xlabel('Private Parameter')\n",
    "plt.ylabel('Misclassification Error Rate')\n",
    "plt.legend(['NonPrivate','Objective Perturbation','Output Perturbation'], loc='upper center')\n",
    "plt.savefig('error_rate_FastFood_best_Lambda.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "error_rks = [error_nonpriv_rks_cv] * 11\n",
    "plt.plot(epsilon, error_rks)\n",
    "plt.plot(epsilon, error_rks_obj_fixed_lambda)\n",
    "plt.plot(epsilon, error_rks_out_fixed_lambda)\n",
    "# plt.ylim(0, 0.1)\n",
    "my_xticks = ['0.01', '0.05', '0.1', '0.15', '0.2', '0.25', '0.3', '0.35', '0.4', '0.45', '0.5']\n",
    "plt.xticks(epsilon, my_xticks)\n",
    "plt.xlabel('Private Parameter')\n",
    "plt.ylabel('Misclassification Error Rate')\n",
    "plt.legend(['NonPrivate','Objective Perturbation','Output Perturbation'], loc='upper center')\n",
    "plt.savefig('error_rate_RKS_best_Lambda.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
